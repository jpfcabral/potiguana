{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qqqU PyPDF2 langchain langchain-community matplotlib pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"../data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf\")\n",
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\n",
    "\n",
    "for i in range(len(reader.pages)):\n",
    "    page = reader.pages[i]\n",
    "    text = page.extract_text()\n",
    "    text.strip()\n",
    "\n",
    "    raw_text += text\n",
    "\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('TÍTULO', pos)]\n",
    "capitulo_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('CAPÍTULO', pos)]\n",
    "secoes_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('Seção', pos)]\n",
    "subsecao_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('Subseção', pos)]\n",
    "artigo_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('Art.', pos)]\n",
    "# paragrafo_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('Parágrafo único.', pos)]\n",
    "# p_starts = [pos for pos, _ in enumerate(raw_text) if raw_text.startswith('§', pos)]\n",
    "\n",
    "section_starts = titulo_starts + secoes_starts + artigo_starts + capitulo_starts +subsecao_starts\n",
    "section_starts.sort()\n",
    "splits = []\n",
    "\n",
    "for i in range(len(section_starts) - 1):\n",
    "    section = raw_text[section_starts[i]:section_starts[i+1]]\n",
    "    splits.append(section)\n",
    "\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def create_dictionary(strings_list):\n",
    "    document_dict = {}\n",
    "    current_title = None\n",
    "    current_chapter = None\n",
    "    current_section = None\n",
    "    current_subsection = None\n",
    "\n",
    "    for string in strings_list:\n",
    "        string = string.strip().replace('\\n', '')\n",
    "\n",
    "        # Identifica títulos\n",
    "        if string.startswith('TÍTULO'):\n",
    "            current_title = string\n",
    "            current_chapter = None\n",
    "            current_section = None\n",
    "            current_subsection = None\n",
    "            document_dict[current_title] = {}\n",
    "\n",
    "        # Identifica capítulos\n",
    "        elif string.startswith('CAPÍTULO'):\n",
    "            if current_title:\n",
    "                current_chapter = string\n",
    "                current_section = None\n",
    "                current_subsection = None\n",
    "                document_dict[current_title][current_chapter] = {}\n",
    "\n",
    "        # Identifica seções\n",
    "        elif string.startswith('Seção'):\n",
    "            if current_title and current_chapter:\n",
    "                current_section = string\n",
    "                current_subsection = None\n",
    "                document_dict[current_title][current_chapter][current_section] = {}\n",
    "\n",
    "        # Identifica subseções\n",
    "        elif string.startswith('Subseção'):\n",
    "            if current_title and current_chapter and current_section:\n",
    "                current_subsection = string\n",
    "                document_dict[current_title][current_chapter][current_section][current_subsection] = {}\n",
    "\n",
    "        # Identifica artigos\n",
    "        elif string.startswith('Art'):\n",
    "            if current_title and current_chapter and current_section and current_subsection:\n",
    "                document_dict[current_title][current_chapter][current_section][current_subsection] = string\n",
    "            elif current_title and current_chapter and current_section:\n",
    "                document_dict[current_title][current_chapter][current_section][string] = None\n",
    "            elif current_title and current_chapter:\n",
    "                document_dict[current_title][current_chapter][string] = None\n",
    "            elif current_title:\n",
    "                document_dict[current_title][string] = None\n",
    "            else:\n",
    "                # Caso o artigo esteja fora de um título definido\n",
    "                document_dict[string] = None\n",
    "\n",
    "    return document_dict\n",
    "\n",
    "document_dict = create_dictionary(splits)\n",
    "json_like = json.dumps(document_dict, indent=4, ensure_ascii=False)\n",
    "print(json_like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "for k, v in document_dict.items():\n",
    "    if v is None:\n",
    "        articles.append(k)\n",
    "    elif isinstance(v, dict):\n",
    "        for k2, v2 in v.items():\n",
    "            if v2 is None:\n",
    "                articles.append(k2)\n",
    "            else:\n",
    "                articles.append(v2)\n",
    "\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Caminho do arquivo PDF\n",
    "pdf_path = \"../data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf\"\n",
    "\n",
    "# Carregar o PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Configurações de tamanhos de chunk para comparação\n",
    "chunk_sizes = [200, 500, 1000, 2000]  # Tamanhos de chunks para análise\n",
    "chunk_overlap = 50  # Mesma sobreposição para todos os casos\n",
    "\n",
    "# Armazenar resultados\n",
    "chunk_distributions = {}\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    chunk_distributions[size] = [len(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# Gerar gráfico comparativo\n",
    "plt.figure(figsize=(12, 8))\n",
    "for size, sizes_list in chunk_distributions.items():\n",
    "    plt.plot(range(len(sizes_list)), sizes_list, label=f\"Tamanho de Chunk = {size}\")\n",
    "\n",
    "plt.title(\"Comparação de Distribuição de Tamanhos de Chunks\")\n",
    "plt.xlabel(\"Índice do Chunk\")\n",
    "plt.ylabel(\"Tamanho do Chunk\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Configurações de tamanhos de chunk para comparação\n",
    "chunk_sizes = [200, 500, 1000, 2000]  # Tamanhos de chunks para análise\n",
    "chunk_overlap = 50  # Mesma sobreposição para todos os casos\n",
    "\n",
    "# Armazenar resultados\n",
    "chunk_counts = []  # Armazena o número total de chunks para cada tamanho\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    chunk_counts.append(len(chunks))\n",
    "\n",
    "# Criar o gráfico de barras agrupadas\n",
    "x = np.arange(len(chunk_sizes))  # Posições no eixo X\n",
    "bar_width = 0.6\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, chunk_counts, width=bar_width, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Adicionar rótulos e títulos\n",
    "plt.xticks(x, [f\"{size}\" for size in chunk_sizes])\n",
    "plt.title(\"Comparação do Número de Chunks por Tamanho\", fontsize=14)\n",
    "plt.xlabel(\"Tamanho do Chunk\", fontsize=12)\n",
    "plt.ylabel(\"Quantidade de Chunks\", fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Exibir os valores acima das barras\n",
    "for i, count in enumerate(chunk_counts):\n",
    "    plt.text(x[i], count + 1, str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import re\n",
    "\n",
    "documents = []\n",
    "metadata = {}\n",
    "\n",
    "for text in splits:\n",
    "\n",
    "    if text.startswith('TÍTULO'):\n",
    "        match = re.match(r\"TÍTULO\\s+([IVXLCDM]+)\\s+(.*)\", text)\n",
    "        numero_titulo = match.group(1).strip()\n",
    "        descricao_titulo = match.group(2).strip()\n",
    "        metadata['Título'] = numero_titulo + \" - \" + descricao_titulo\n",
    "\n",
    "        metadata.pop('Capítulo', None)\n",
    "        metadata.pop('Seção', None)\n",
    "        metadata.pop('Subseção', None)\n",
    "\n",
    "    elif text.startswith('CAPÍTULO'):\n",
    "        match = re.match(r\"CAPÍTULO\\s+([IVXLCDM]+)\\s+(.*)\", text)\n",
    "        numero_capitulo = match.group(1).strip()\n",
    "        descricao_capitulo = match.group(2).strip()\n",
    "        metadata['Capítulo'] = numero_capitulo + \" - \" + descricao_capitulo\n",
    "\n",
    "        metadata.pop('Seção', None)\n",
    "        metadata.pop('Subseção', None)\n",
    "\n",
    "    elif text.startswith('Seção'):\n",
    "        match = re.match(r\"Seção\\s+([IVXLCDM]+)\\s+(.*)\", text)\n",
    "        numero_secao = match.group(1).strip()\n",
    "        descricao_secao = match.group(2).strip()\n",
    "        metadata['Seção'] = numero_secao + \" - \" + descricao_secao\n",
    "\n",
    "        metadata.pop('Subseção', None)\n",
    "\n",
    "    elif text.startswith('Subseção'):\n",
    "        match = re.match(r\"Subseção\\s+([IVXLCDM]+)\\s+(.*)\", text)\n",
    "        numero_subsecao = match.group(1).strip()\n",
    "        descricao_subsecao = match.group(2).strip()\n",
    "        metadata['Seção'] = numero_subsecao + \" - \" + descricao_subsecao\n",
    "\n",
    "\n",
    "    elif text.startswith('Art.'):\n",
    "        match = re.match(r\"Art\\.\\s*(\\d+)\", text)\n",
    "        final_art_number_chat = match.span(0)[-1]\n",
    "        art_number = match.group(1)\n",
    "\n",
    "        metadata[\"Artigo\"] = art_number\n",
    "\n",
    "        art_content: str = text[final_art_number_chat:]\n",
    "        art_content: str = art_content.replace('º', '').replace('\\n', '').lstrip(\" .\").strip()\n",
    "        \n",
    "        document = Document(\n",
    "            page_content=art_content,\n",
    "            metadata=metadata\n",
    "            )\n",
    "\n",
    "        documents.append(document)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    region_name='us-east-1',\n",
    "    )\n",
    "\n",
    "client = QdrantClient(\n",
    "    location=os.environ[\"VECTOR_STORE_URL\"],\n",
    "    api_key=os.environ[\"VECTOR_STORE_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Create collection\n",
    "# client.create_collection(\n",
    "#     collection_name=\"regulamento_dos_cursos_de_graduacao_da_UFRN\",\n",
    "#     vectors_config=VectorParams(size=len(embeddings.embed_query(\" \")), distance=Distance.COSINE),\n",
    "# )\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"regulamento_dos_cursos_de_graduacao_da_UFRN\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qqqU python-dotenv langchain langchain-openai ragas chromadb wandb tiktoken openai jq rapidfuzz jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.schema import Document\n",
    "def load_documents(json_path: str = './data/regulamento-semantic.json'):\n",
    "    documents = []\n",
    "    \n",
    "    # Abrindo e lendo o arquivo JSON\n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line.strip())\n",
    "            \n",
    "            # Criando o documento LangChain\n",
    "            doc = Document(\n",
    "                page_content=data.get(\"page_content\", \"\"),\n",
    "                metadata=data.get(\"metadata\", {})\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "docs = load_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating pt to english due RAGAS constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "\n",
    "def translate_documents_to_english_langchain(documents, model_name=\"gpt-4o-mini\"):\n",
    "    llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "\n",
    "    translated_documents = []\n",
    "\n",
    "    for doc in documents:\n",
    "        if not isinstance(doc, Document):\n",
    "            raise ValueError(\"Os documentos devem ser instâncias da classe Document.\")\n",
    "        \n",
    "        # Mensagem para o modelo\n",
    "        translation_prompt = f\"Por favor, traduza o seguinte texto para inglês:\\n\\n{doc.page_content}\"\n",
    "\n",
    "        # Realiza a tradução\n",
    "        try:\n",
    "            translated_text = llm.predict(translation_prompt)\n",
    "            # Cria um novo documento traduzido\n",
    "            translated_doc = Document(page_content=translated_text, metadata=doc.metadata)\n",
    "            translated_documents.append(translated_doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao traduzir o documento: {e}\")\n",
    "            # Preserva o documento original em caso de erro\n",
    "            translated_documents.append(Document(page_content=doc.page_content, metadata={**doc}))\n",
    "\n",
    "    return translated_documents\n",
    "\n",
    "\n",
    "translated_docs = translate_documents_to_english_langchain(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import jsonlines\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def save_docs_to_jsonl(documents: t.Iterable[Document], file_path: str) -> None:\n",
    "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
    "        for doc in documents:\n",
    "            writer.write(doc.dict())\n",
    "\n",
    "\n",
    "def load_docs_from_jsonl(file_path) -> t.Iterable[Document]:\n",
    "    documents = []\n",
    "    with jsonlines.open(file_path, mode=\"r\") as reader:\n",
    "        for doc in reader:\n",
    "            documents.append(Document(**doc))\n",
    "    return documents\n",
    "\n",
    "# save_docs_to_jsonl(translated_docs, '../regulamento-docs-eng.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_docs = load_docs_from_jsonl('../regulamento-docs-eng.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.2,  # <-- Can only make a request once every 10 seconds!!\n",
    "    check_every_n_seconds=0.1,  # Wake up every 100 ms to check whether allowed to make a request,\n",
    "    max_bucket_size=10,  # Controls the maximum burst size.\n",
    ")\n",
    "\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\", rate_limiter=rate_limiter))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "personas = [\n",
    "    Persona(\n",
    "        name=\"student\",\n",
    "        role_description=\"An undergraduate student at UFRN who has questions about academic rules and regulations with no context about it, do not mention articles directly \",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings, persona_list=personas)\n",
    "dataset = generator.generate_with_langchain_docs(translated_docs, testset_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.to_csv(\"../ragas_openai_gpt4o-en.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating english to portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def translate_ragas_dataframe_to_portuguese(df, model_name=\"gpt-4o-mini\"):\n",
    "\n",
    "    # Inicializa o modelo OpenAI via LangChain\n",
    "    llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "\n",
    "    # Função auxiliar para traduzir texto\n",
    "    def translate_text(text, column_name):\n",
    "        try:\n",
    "            # Monta o prompt para tradução\n",
    "            prompt = f\"Translate the following text to Portuguese:\\n\\n{text}\"\n",
    "            result = llm.predict(prompt)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao traduzir a coluna {column_name}: {e}\")\n",
    "            return text  # Retorna o texto original em caso de erro\n",
    "\n",
    "    # Cria cópia do DataFrame para evitar alterações no original\n",
    "    translated_df = df.copy()\n",
    "\n",
    "    # Tradução das colunas\n",
    "    for column in ['user_input', 'reference_contexts', 'reference']:\n",
    "        if column in df.columns:\n",
    "            translated_df[column] = df[column].apply(lambda x: translate_text(x, column))\n",
    "        else:\n",
    "            print(f\"A coluna {column} não foi encontrada no DataFrame.\")\n",
    "\n",
    "    return translated_df\n",
    "\n",
    "translated_df = translate_ragas_dataframe_to_portuguese(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_df.to_csv('../ragas_openai_gpt4o-pt.csv')\n",
    "translated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
